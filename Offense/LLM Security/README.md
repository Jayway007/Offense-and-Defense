# AI Security
## Resources
![image](https://github.com/user-attachments/assets/191863bd-2a09-420b-a4f3-22e8422d453a)

- The AI Attack Surface Map v1.0:  https://danielmiessler.com/p/the-ai-attack-surface-map-v1-0/
- Prompt Injection Attacks and Mitigations from rez0:  https://josephthacker.com/ai/2023/04/19/prompt-injection-and-mitigations.html
- NISTâ€™s document about AI security defines terminology:  https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf
- Every AI Talk from BSidesLV, Black Hat, and DEF CON 2024: https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/


## Cases
- They Hacked Google A.I. for $50,000: https://www.landh.tech/blog/20240304-google-hack-50000/
- Hacking Google Bard - From Prompt Injection to Data Exfiltration: https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/
- When Prompts Go Rogue: Analyzing a Prompt Injection Code Execution in Vanna.AI: https://jfrog.com/blog/prompt-injection-attack-code-execution-in-vanna-ai-cve-2024-5565/


## Tools
- https://github.com/Azure/PyRIT


# LLM
- https://socradar.io/owasp-top-10-or-llms/
- https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v05.pdf


## CTF 
- https://www.aicrowd.com/challenges/hackaprompt-2023
